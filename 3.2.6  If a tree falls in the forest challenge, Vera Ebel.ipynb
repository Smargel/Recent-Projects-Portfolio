{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ebel\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#based on https://www.quora.com/How-can-l-visualize-cifar-10-data-RGB-using-python-matplotlib\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict1 = pickle.load(fo, encoding='bytes')\n",
    "    return dict1\n",
    "#Create the dataframes \n",
    "pd_tr = pd.DataFrame()\n",
    "tr_y = pd.DataFrame()\n",
    "#Reading files 1-5\n",
    "for i in range(1,5):\n",
    "    data = unpickle(r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\data_batch_\" + str(i))\n",
    "    #Place the data matrix as the training data \n",
    "    pd_tr = pd_tr.append(pd.DataFrame(data[b'data']))\n",
    "    #Read the data matrix labels as the Y variable\n",
    "    tr_y = tr_y.append(pd.DataFrame(data[b'labels']))\n",
    "    #Turning the dataframe of the dataframe into a column of the original dataframe, merging them. \n",
    "    pd_tr['labels'] = tr_y\n",
    "\n",
    "tr_x = np.asarray(pd_tr.iloc[:, :3072])\n",
    "tr_y = np.asarray(pd_tr['labels'])\n",
    "#Reading the test batch as a test data frame. \n",
    "ts_x = np.asarray(unpickle(r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\test_batch\")[b'data'])\n",
    "ts_y = np.asarray(unpickle(r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\test_batch\")[b'labels'])    \n",
    "labels = unpickle(r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\batches.meta\")[b'label_names']\n",
    "\n",
    "def plot_CIFAR(ind):\n",
    "    #Turn the index of the training data into an array. \n",
    "    arr = tr_x[ind]\n",
    "    #Reshaping each RGB section into their 32*32 respective matrixes, making them representative of the pixels \n",
    "    #they're supposed to represent.\n",
    "    R = arr[0:1024].reshape(32,32)/255.0\n",
    "    G = arr[1024:2048].reshape(32,32)/255.0\n",
    "    B = arr[2048:].reshape(32,32)/255.0\n",
    "    #Plotting out the pixels into an image for testing \n",
    "    #making RGB stack on top of eachother, producing the spectrum of color. \n",
    "    img = np.dstack((R,G,B))\n",
    "    title = re.sub('[!@#$b]', '', str(labels[tr_y[ind]]))\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,interpolation='bicubic')\n",
    "    ax.set_title('Category = '+ title,fontsize =15)\n",
    "#Ploting 4th image in the data set. \n",
    "plot_CIFAR(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames']) \n",
      "\n",
      "b'batch_label' <class 'bytes'> 21\n",
      "b'labels' <class 'list'> 10000\n",
      "b'data' <class 'numpy.ndarray'> 10000\n",
      "b'filenames' <class 'list'> 10000\n"
     ]
    }
   ],
   "source": [
    "pd_tr = pd.DataFrame()\n",
    "tr_y = pd.DataFrame()\n",
    "\n",
    "file = r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\data_batch_1\"\n",
    "with open(file, 'rb') as fo:\n",
    "    dict1 = pickle.load(fo, encoding='bytes')\n",
    "print(dict1.keys(), '\\n')\n",
    "for key in dict1.keys():\n",
    "    print(key, type(dict1[key]), len(dict1[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3073)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>180</td>\n",
       "      <td>177</td>\n",
       "      <td>175</td>\n",
       "      <td>173</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>66</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>104</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>99</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>108</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...    3063  3064  3065  \\\n",
       "0  178  178  178  178  179  179  179  180  180  180   ...      83    86    86   \n",
       "1   29   22   25   24   28   43   94  139  133  133   ...      17    17    21   \n",
       "2   36   33   21   20   52   54   19   22   19   20   ...     183   181   181   \n",
       "3   30   45   44   50   71   64   29   66   87   87   ...      98   100   107   \n",
       "4   35   80   89   52   47   39   50   79  134  135   ...     146   108    85   \n",
       "\n",
       "   3066  3067  3068  3069  3070  3071  labels  \n",
       "0    84    82    80    80    80    77       0  \n",
       "1    24    26    29    29    31    30       6  \n",
       "2   180   177   175   173   170   170       0  \n",
       "3   109   104   107   106    99   147       2  \n",
       "4    81    99   104   107   110    92       7  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tr = pd_tr.append(pd.DataFrame(data[b'data']))\n",
    "tr_y = tr_y.append(pd.DataFrame(data[b'labels']))\n",
    "pd_tr['labels'] = tr_y\n",
    "print(pd_tr.shape)\n",
    "pd_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3073)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>104</td>\n",
       "      <td>140</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>67</td>\n",
       "      <td>101</td>\n",
       "      <td>122</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>154</td>\n",
       "      <td>138</td>\n",
       "      <td>184</td>\n",
       "      <td>154</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>164</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>129</td>\n",
       "      <td>134</td>\n",
       "      <td>146</td>\n",
       "      <td>166</td>\n",
       "      <td>183</td>\n",
       "      <td>199</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>97</td>\n",
       "      <td>113</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>134</td>\n",
       "      <td>131</td>\n",
       "      <td>128</td>\n",
       "      <td>133</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>134</td>\n",
       "      <td>121</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>233</td>\n",
       "      <td>224</td>\n",
       "      <td>208</td>\n",
       "      <td>145</td>\n",
       "      <td>116</td>\n",
       "      <td>128</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125</td>\n",
       "      <td>110</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>141</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>148</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...    3063  3064  3065  \\\n",
       "0   59   43   50   68   98  119  139  145  149  149   ...      58    65    59   \n",
       "1  154  126  105  102  125  155  172  180  142  111   ...      42    67   101   \n",
       "2  255  253  253  253  253  253  253  253  253  253   ...      83    80    69   \n",
       "3   28   37   38   42   44   40   40   24   32   43   ...      39    59    42   \n",
       "4  170  168  177  183  181  177  181  184  189  189   ...      88    85    82   \n",
       "5  159  150  153  154  138  184  154   77   61   64   ...      18    16    12   \n",
       "6  164  105  118  129  134  146  166  183  199  174   ...      71    48    58   \n",
       "7   28   30   33   62   63   31   29   42   55   67   ...      83   107   110   \n",
       "8  134  131  128  133  139  140  134  121  124  124   ...     233   224   208   \n",
       "9  125  110  102  106  106  141  175  175  148  106   ...      62    67    70   \n",
       "\n",
       "   3066  3067  3068  3069  3070  3071  labels  \n",
       "0    46    57   104   140    84    72       6  \n",
       "1   122   133   136   139   142   144       9  \n",
       "2    66    72    79    83    83    84       9  \n",
       "3    44    48    38    28    37    46       4  \n",
       "4    83    79    78    82    78    80       1  \n",
       "5    13    16    14    14    17    19       1  \n",
       "6    64    48    41    29    26    44       2  \n",
       "7    97   113   117   100    99    96       7  \n",
       "8   145   116   128   136   137   138       8  \n",
       "9    75    79    81    82    84    86       3  \n",
       "\n",
       "[10 rows x 3073 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tr = pd.DataFrame()\n",
    "tr_y = pd.DataFrame()\n",
    "\n",
    "for i in range(1,5):\n",
    "    data = unpickle(r\"C:\\Users\\Ebel\\Downloads\\cifar-10-python.tar\\cifar-10-batches-py\\data_batch_\" + str(i))\n",
    "    pd_tr = pd_tr.append(pd.DataFrame(data[b'data']))\n",
    "    tr_y = tr_y.append(pd.DataFrame(data[b'labels']))\n",
    "    pd_tr['labels'] = tr_y\n",
    "print(pd_tr.shape)\n",
    "pd_tr.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first want to experiment a bit with a MLPClassifier to see how well a normal network does in a supervised envioerment with this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  pd_tr.loc[:, pd_tr.columns != 'labels'], pd_tr['labels'], test_size=0.2)\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model with 3 1000 perceptron layers.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1000, 3))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's supicsious... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>213</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>157</td>\n",
       "      <td>123</td>\n",
       "      <td>143</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "      <td>158</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>92</td>\n",
       "      <td>203</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "      <td>103</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...   3062  \\\n",
       "5147   211   211   211   213   216   217   218   219   219   219  ...      9   \n",
       "1081   157   123   143   137   126   130   158   163   135   131  ...     38   \n",
       "105    254   254   254   254   254   254   254   254   254   254  ...    253   \n",
       "2009   187   188   189   189   189   189   189   189   189   190  ...     71   \n",
       "2205    63    24    23    27    38    36    31    92   203   220  ...    114   \n",
       "\n",
       "      3063  3064  3065  3066  3067  3068  3069  3070  3071  \n",
       "5147    12    17    15    10     9    19    20    13    12  \n",
       "1081    45    63    70    48    54    49    29    29    50  \n",
       "105    253   253   254   254   254   254   254   254   254  \n",
       "2009    69    69    71    74    77    80    83    80    81  \n",
       "2205   112   112   112   105   109   120   115   103   108  \n",
       "\n",
       "[5 rows x 3072 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5147    0\n",
       "1081    4\n",
       "105     1\n",
       "2009    0\n",
       "2205    2\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000))\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2495"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(3000))\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's about as high as I could get it in a reasonable amount of time spent compiling. I think that's not as bad as it seems, given that there are ten potential labels to attach to an image, so if we were guessing completely randomly we could expect a result around 10%. Still, it's not accurate enough to be useful. Regardless, I'll move on to feature extraction, then using a traditional classification model following it and see where that takes me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.3, n_components=256, n_iter=10,\n",
       "       random_state=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "RBM = BernoulliRBM(n_components=256, learning_rate=.3)\n",
    "RBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 10,\n",
       " 'learning_rate': 0.3,\n",
       " 'n_components': 256,\n",
       " 'n_iter': 10,\n",
       " 'random_state': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBM.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -0.00000000e+00, -0.00000000e+00, ...,\n",
       "       -0.00000000e+00, -0.00000000e+00, -1.28939561e+14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBM.score_samples(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I realized that I needed to normalize the data before feeding it into the RBM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. preprocessing import normalize\n",
    "\n",
    "X = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.3, n_components=256, n_iter=10,\n",
       "       random_state=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBM.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ebel\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RTC = RandomForestClassifier(n_estimators=75, max_features=None)\n",
    "rbm_class_generator = Pipeline(steps=[('RBM', RBM), ('Random_Tree_Classifier', RTC)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('RBM', BernoulliRBM(batch_size=10, learning_rate=0.3, n_components=256, n_iter=10,\n",
       "       random_state=None, verbose=0)), ('Random_Tree_Classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm_class_generator.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       782\n",
      "          1       0.00      0.00      0.00       790\n",
      "          2       0.00      0.00      0.00       835\n",
      "          3       0.00      0.00      0.00       770\n",
      "          4       0.00      0.00      0.00       843\n",
      "          5       0.00      0.00      0.00       824\n",
      "          6       0.00      0.00      0.00       775\n",
      "          7       0.00      0.00      0.00       781\n",
      "          8       0.10      1.00      0.19       827\n",
      "          9       0.00      0.00      0.00       773\n",
      "\n",
      "avg / total       0.01      0.10      0.02      8000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ebel\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Y_pred = rbm_class_generator.predict(X_test)\n",
    "print(\"Random Forest Classification using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm reading this as \"really bad.\" It looks like the model isn't getting any precisions except on 8. In fact, it seems like it's possible that it's marking literally everything as \"8,\" and 10% happened to be right given the distribution of the dataset labels. I think I might have to either adjust the model or the pipeline that fed into it. I'll keep working on it, maybe try different models, but if you spot something obvious I did wrong, or think I interpreted the .metrics report wrong then we can talk about it. Technically this might complete the assignment, albeit poorly, so I'll move on to some other assignments until then. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because I'm interested in getting your input on this, and because it's not hard to tack on, I'll complete the random forest assignment here, by running a computationally intensive model with no limitations, then a very inaccurate model with lots of limitations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classification predicting labels raw pixel features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.52      0.51       782\n",
      "          1       0.48      0.53      0.50       790\n",
      "          2       0.39      0.35      0.37       835\n",
      "          3       0.30      0.27      0.28       770\n",
      "          4       0.39      0.37      0.38       843\n",
      "          5       0.39      0.36      0.37       824\n",
      "          6       0.43      0.51      0.47       775\n",
      "          7       0.48      0.44      0.46       781\n",
      "          8       0.57      0.57      0.57       827\n",
      "          9       0.47      0.53      0.49       773\n",
      "\n",
      "avg / total       0.44      0.44      0.44      8000\n",
      "\n",
      "\n",
      "5291.5778205394745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "raw_classifier = clone(RTC)\n",
    "\n",
    "raw_classifier.fit(X_train, y_train)\n",
    "Y_pred = raw_classifier.predict(X_test)\n",
    "print(\"Random forest classification predicting labels raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(y_test, Y_pred)))\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classification done very cheaply\n",
      "0.2595\n",
      "0.7055613994598389\n"
     ]
    }
   ],
   "source": [
    "RTCheap= RandomForestClassifier(n_estimators=10, max_features=5, max_depth= 3)\n",
    "start = time.time()\n",
    "RTCheap.fit(X_train, y_train)\n",
    "print(\"Random forest classification done very cheaply\")\n",
    "print(RTCheap.score(X_test, y_test))\n",
    "stop = time.time()\n",
    "print(stop-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd probably follow this up a with a cross fold validation, but I'm not sure if I'm confident enough in my model to commit to something that computationally intensive, I think I need to get better at understanding the results from .metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
